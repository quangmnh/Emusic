{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Script to obtain data \r\n",
    "from helpers import *\r\n",
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "#Libraries to create the multiclass model\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
    "from keras.utils import np_utils\r\n",
    "#Import tensorflow and disable the v2 behavior and eager mode\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.layers import LeakyReLU, Dense\r\n",
    "from tensorflow.keras.optimizers import SGD\r\n",
    "tf.compat.v1.disable_eager_execution()\r\n",
    "tf.compat.v1.disable_v2_behavior()\r\n",
    "\r\n",
    "#Library to validate the model\r\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\r\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
    "from sklearn.utils import compute_class_weight\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv(\"data/train_2.csv\")"
   ],
   "outputs": [],
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "col_features = df.columns[6:-2]\r\n",
    "print((col_features))\r\n",
    "X= MinMaxScaler().fit_transform(df[col_features])\r\n",
    "X2 = np.array(df[col_features])\r\n",
    "Y = df['mood']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['duration', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
      "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
      "       'valence', 'tempo', 'time_signature'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Encodethe categories\r\n",
    "encoder = LabelEncoder()\r\n",
    "encoder.fit(Y)\r\n",
    "encoded_y = encoder.transform(Y)\r\n",
    "\r\n",
    "\r\n",
    "#Convert to  dummy (Not necessary in my case)\r\n",
    "dummy_y = np_utils.to_categorical(encoded_y)\r\n",
    "classWeight = compute_class_weight('balanced', np.unique(encoded_y), encoded_y)\r\n",
    "classWeight = dict(enumerate(classWeight))\r\n",
    "print(classWeight)\r\n",
    "\r\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,encoded_y,test_size=0.2,random_state=15)\r\n",
    "# Convert to dummy, no needed for now\r\n",
    "# Y_train = np_utils.to_categorical(Y_train)\r\n",
    "# Y_test = np_utils.to_categorical(Y_test)\r\n",
    "target = pd.DataFrame({'mood':df['mood'].tolist(),'encode':encoded_y}).drop_duplicates().sort_values(['encode'],ascending=True)\r\n",
    "target"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3], y=[1 3 2 ... 0 3 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: 0.9174497862386061, 1: 2.090163557842507, 2: 0.8652434385697984, 3: 0.7837933291985391}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mood</th>\n",
       "      <th>encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>calm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>energetic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mood  encode\n",
       "6       calm       0\n",
       "0  energetic       1\n",
       "2      happy       2\n",
       "1        sad       3"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "leaky_relu = LeakyReLU(alpha=0.01)\r\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\r\n",
    "opt = SGD(lr=0.01)\r\n",
    "\r\n",
    "def base_model():\r\n",
    "    #Create the model\r\n",
    "    model = Sequential()\r\n",
    "    # Add 1 layer with 8 nodes,input of 4 dim with relu function\r\n",
    "    # Oct 1st: Changed to 10 nodes\r\n",
    "    # Oct 14th: Changed to 8 nodes, removed the duplicate data\r\n",
    "    model.add(Dense(10,input_dim=13,activation='relu'))\r\n",
    "    #Add 1 layer with output of 4 and softmax activation function\r\n",
    "    model.add(Dense(4,activation='softmax'))\r\n",
    "    # model.add(Dense(4,activation='softmax'))\r\n",
    "    #Compile the model using sigmoid loss function and adam optim\r\n",
    "    # sgd optimizer improve the accuracy on the author's dataset\r\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',\r\n",
    "                 metrics=['accuracy'])\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# leaky_relu = LeakyReLU(alpha=0.01)\r\n",
    "# sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\r\n",
    "# opt = SGD(lr=0.01)\r\n",
    "\r\n",
    "# #Create the model\r\n",
    "# model = Sequential()\r\n",
    "# # Add 1 layer with 8 nodes,input of 4 dim with relu function\r\n",
    "# # Oct 1st: Changed to 10 nodes\r\n",
    "# # Oct 14th: Changed to 8 nodes, removed the duplicate data\r\n",
    "# model.add(Dense(8,input_dim=13,activation='relu'))\r\n",
    "# #Add 1 layer with output of 4 and softmax activation function\r\n",
    "# model.add(Dense(4,activation='softmax'))\r\n",
    "# # model.add(Dense(4,activation='softmax'))\r\n",
    "# #Compile the model using sigmoid loss function and adam optim\r\n",
    "# # sgd optimizer improve the accuracy on the author's dataset\r\n",
    "# model.compile(loss='categorical_crossentropy',optimizer=sgd,\r\n",
    "#                 metrics=['accuracy'])\r\n",
    "\r\n",
    "# # Train the model\r\n",
    "# model.fit(X_train, Y_train, \r\n",
    "#             batch_size=256, \r\n",
    "#             epochs=300, \r\n",
    "#             verbose=1, \r\n",
    "#             class_weight=classWeight,    \r\n",
    "#             validation_data=(X_test, Y_test),\r\n",
    "#             shuffle=True)\r\n",
    "# model.evaluate(X_test, Y_test, verbose=1)\r\n",
    "# y_preds = model.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#Configure the model\r\n",
    "# increase batch size for the warning: WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update\r\n",
    "estimator = KerasClassifier(build_fn=base_model,epochs=30,batch_size=512,verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#Evaluate the model using KFold cross validation\r\n",
    "kfold = KFold(n_splits=10,shuffle=True)\r\n",
    "# results = cross_val_score(estimator,X,encoded_y,cv=kfold)\r\n",
    "results = cross_val_score(estimator,X,dummy_y,cv=kfold)\r\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 81890 samples\n",
      "Epoch 1/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.3363 - acc: 0.3137\n",
      "Epoch 2/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.2252 - acc: 0.4498\n",
      "Epoch 3/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1796 - acc: 0.4758\n",
      "Epoch 4/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1616 - acc: 0.4870\n",
      "Epoch 5/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1530 - acc: 0.4920\n",
      "Epoch 6/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1481 - acc: 0.4951\n",
      "Epoch 7/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1447 - acc: 0.4979\n",
      "Epoch 8/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1421 - acc: 0.4992\n",
      "Epoch 9/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1401 - acc: 0.5007\n",
      "Epoch 10/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1379 - acc: 0.5026\n",
      "Epoch 11/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1360 - acc: 0.5028\n",
      "Epoch 12/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1340 - acc: 0.5043\n",
      "Epoch 13/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1326 - acc: 0.5047\n",
      "Epoch 14/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1309 - acc: 0.5055\n",
      "Epoch 15/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1295 - acc: 0.5063\n",
      "Epoch 16/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1285 - acc: 0.5068\n",
      "Epoch 17/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1273 - acc: 0.5069\n",
      "Epoch 18/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1263 - acc: 0.5070\n",
      "Epoch 19/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1254 - acc: 0.5067\n",
      "Epoch 20/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1244 - acc: 0.5074\n",
      "Epoch 21/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1240 - acc: 0.5073\n",
      "Epoch 22/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1231 - acc: 0.5078\n",
      "Epoch 23/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1225 - acc: 0.5074\n",
      "Epoch 24/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1219 - acc: 0.5075\n",
      "Epoch 25/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1214 - acc: 0.5079\n",
      "Epoch 26/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1210 - acc: 0.5086\n",
      "Epoch 27/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1205 - acc: 0.5080\n",
      "Epoch 28/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1201 - acc: 0.5082\n",
      "Epoch 29/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1197 - acc: 0.5080\n",
      "Epoch 30/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1193 - acc: 0.5086\n",
      "Train on 81890 samples\n",
      "Epoch 1/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.3459 - acc: 0.3553\n",
      "Epoch 2/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.2265 - acc: 0.4536\n",
      "Epoch 3/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1830 - acc: 0.4845\n",
      "Epoch 4/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1625 - acc: 0.4943\n",
      "Epoch 5/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1517 - acc: 0.4968\n",
      "Epoch 6/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1464 - acc: 0.4990\n",
      "Epoch 7/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1430 - acc: 0.5004\n",
      "Epoch 8/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1408 - acc: 0.5011\n",
      "Epoch 9/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1389 - acc: 0.5013\n",
      "Epoch 10/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1372 - acc: 0.5022\n",
      "Epoch 11/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1357 - acc: 0.5025\n",
      "Epoch 12/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1339 - acc: 0.5031\n",
      "Epoch 13/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1323 - acc: 0.5031\n",
      "Epoch 14/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1307 - acc: 0.5038\n",
      "Epoch 15/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1294 - acc: 0.5044\n",
      "Epoch 16/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1281 - acc: 0.5049\n",
      "Epoch 17/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1271 - acc: 0.5059\n",
      "Epoch 18/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1261 - acc: 0.5058\n",
      "Epoch 19/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1252 - acc: 0.5065\n",
      "Epoch 20/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1243 - acc: 0.5066\n",
      "Epoch 21/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1237 - acc: 0.5065\n",
      "Epoch 22/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1231 - acc: 0.5072\n",
      "Epoch 23/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1227 - acc: 0.5073\n",
      "Epoch 24/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1222 - acc: 0.5076\n",
      "Epoch 25/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1219 - acc: 0.5078\n",
      "Epoch 26/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1216 - acc: 0.5075\n",
      "Epoch 27/30\n",
      "81890/81890 [==============================] - 1s 6us/sample - loss: 1.1211 - acc: 0.5079\n",
      "Epoch 28/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1208 - acc: 0.5078\n",
      "Epoch 29/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1206 - acc: 0.5085\n",
      "Epoch 30/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1203 - acc: 0.5085\n",
      "Train on 81890 samples\n",
      "Epoch 1/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.3380 - acc: 0.3391\n",
      "Epoch 2/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.2197 - acc: 0.4540\n",
      "Epoch 3/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1782 - acc: 0.4872\n",
      "Epoch 4/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1601 - acc: 0.4954\n",
      "Epoch 5/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1541 - acc: 0.4966\n",
      "Epoch 6/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1506 - acc: 0.4965\n",
      "Epoch 7/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1467 - acc: 0.4968\n",
      "Epoch 8/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1436 - acc: 0.4984\n",
      "Epoch 9/30\n",
      "81890/81890 [==============================] - 0s 3us/sample - loss: 1.1414 - acc: 0.4995\n",
      "Epoch 10/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1394 - acc: 0.5005\n",
      "Epoch 11/30\n",
      "81890/81890 [==============================] - 0s 3us/sample - loss: 1.1379 - acc: 0.5003\n",
      "Epoch 12/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1365 - acc: 0.5005\n",
      "Epoch 13/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1354 - acc: 0.5014\n",
      "Epoch 14/30\n",
      "81890/81890 [==============================] - 0s 3us/sample - loss: 1.1343 - acc: 0.5023\n",
      "Epoch 15/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1335 - acc: 0.5020\n",
      "Epoch 16/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1328 - acc: 0.5025\n",
      "Epoch 17/30\n",
      "81890/81890 [==============================] - 0s 3us/sample - loss: 1.1318 - acc: 0.5026\n",
      "Epoch 18/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1313 - acc: 0.5025\n",
      "Epoch 19/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1307 - acc: 0.5036\n",
      "Epoch 20/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1301 - acc: 0.5034\n",
      "Epoch 21/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1298 - acc: 0.5030\n",
      "Epoch 22/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1291 - acc: 0.5037\n",
      "Epoch 23/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1286 - acc: 0.5040\n",
      "Epoch 24/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1283 - acc: 0.5044\n",
      "Epoch 25/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1278 - acc: 0.5046\n",
      "Epoch 26/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1275 - acc: 0.5055\n",
      "Epoch 27/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1272 - acc: 0.5057\n",
      "Epoch 28/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1268 - acc: 0.5059\n",
      "Epoch 29/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1264 - acc: 0.5053\n",
      "Epoch 30/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1261 - acc: 0.5062\n",
      "Train on 81890 samples\n",
      "Epoch 1/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.2842 - acc: 0.4480\n",
      "Epoch 2/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.2068 - acc: 0.4825\n",
      "Epoch 3/30\n",
      "81890/81890 [==============================] - 1s 6us/sample - loss: 1.1669 - acc: 0.4937\n",
      "Epoch 4/30\n",
      "81890/81890 [==============================] - 1s 9us/sample - loss: 1.1562 - acc: 0.4961\n",
      "Epoch 5/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1523 - acc: 0.4972\n",
      "Epoch 6/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1502 - acc: 0.4975\n",
      "Epoch 7/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1483 - acc: 0.4978\n",
      "Epoch 8/30\n",
      "81890/81890 [==============================] - 1s 6us/sample - loss: 1.1469 - acc: 0.4988\n",
      "Epoch 9/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1453 - acc: 0.4989\n",
      "Epoch 10/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1441 - acc: 0.4990\n",
      "Epoch 11/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1426 - acc: 0.5001\n",
      "Epoch 12/30\n",
      "81890/81890 [==============================] - 1s 6us/sample - loss: 1.1409 - acc: 0.5008\n",
      "Epoch 13/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1392 - acc: 0.5008\n",
      "Epoch 14/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1377 - acc: 0.5014\n",
      "Epoch 15/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1362 - acc: 0.5024\n",
      "Epoch 16/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1349 - acc: 0.5024\n",
      "Epoch 17/30\n",
      "81890/81890 [==============================] - 1s 10us/sample - loss: 1.1337 - acc: 0.5035\n",
      "Epoch 18/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1326 - acc: 0.5033\n",
      "Epoch 19/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1316 - acc: 0.5040\n",
      "Epoch 20/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1308 - acc: 0.5045\n",
      "Epoch 21/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1296 - acc: 0.5050\n",
      "Epoch 22/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1286 - acc: 0.5056\n",
      "Epoch 23/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1279 - acc: 0.5061\n",
      "Epoch 24/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1274 - acc: 0.5058\n",
      "Epoch 25/30\n",
      "81890/81890 [==============================] - 1s 6us/sample - loss: 1.1265 - acc: 0.5061\n",
      "Epoch 26/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1259 - acc: 0.5065\n",
      "Epoch 27/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1254 - acc: 0.5065\n",
      "Epoch 28/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1248 - acc: 0.5072\n",
      "Epoch 29/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1245 - acc: 0.5070\n",
      "Epoch 30/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1238 - acc: 0.5079\n",
      "Train on 81890 samples\n",
      "Epoch 1/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.3790 - acc: 0.2849\n",
      "Epoch 2/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.2447 - acc: 0.4388\n",
      "Epoch 3/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.2029 - acc: 0.4811\n",
      "Epoch 4/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1810 - acc: 0.4924\n",
      "Epoch 5/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1687 - acc: 0.4973\n",
      "Epoch 6/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1615 - acc: 0.4965\n",
      "Epoch 7/30\n",
      "81890/81890 [==============================] - 1s 10us/sample - loss: 1.1569 - acc: 0.4965\n",
      "Epoch 8/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1540 - acc: 0.4968\n",
      "Epoch 9/30\n",
      "81890/81890 [==============================] - 1s 9us/sample - loss: 1.1521 - acc: 0.4968\n",
      "Epoch 10/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1507 - acc: 0.4979\n",
      "Epoch 11/30\n",
      "81890/81890 [==============================] - 1s 6us/sample - loss: 1.1499 - acc: 0.4977\n",
      "Epoch 12/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1489 - acc: 0.4981\n",
      "Epoch 13/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1484 - acc: 0.4971\n",
      "Epoch 14/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1479 - acc: 0.4977\n",
      "Epoch 15/30\n",
      "81890/81890 [==============================] - 1s 12us/sample - loss: 1.1472 - acc: 0.4977\n",
      "Epoch 16/30\n",
      "81890/81890 [==============================] - 1s 9us/sample - loss: 1.1465 - acc: 0.4979\n",
      "Epoch 17/30\n",
      "81890/81890 [==============================] - 1s 11us/sample - loss: 1.1459 - acc: 0.4982\n",
      "Epoch 18/30\n",
      "81890/81890 [==============================] - 1s 9us/sample - loss: 1.1454 - acc: 0.4980\n",
      "Epoch 19/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1448 - acc: 0.4988\n",
      "Epoch 20/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1443 - acc: 0.4992\n",
      "Epoch 21/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1436 - acc: 0.4994\n",
      "Epoch 22/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1432 - acc: 0.4998\n",
      "Epoch 23/30\n",
      "81890/81890 [==============================] - 0s 3us/sample - loss: 1.1425 - acc: 0.5010\n",
      "Epoch 24/30\n",
      "81890/81890 [==============================] - 0s 3us/sample - loss: 1.1421 - acc: 0.5001\n",
      "Epoch 25/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1414 - acc: 0.5013\n",
      "Epoch 26/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1409 - acc: 0.5018\n",
      "Epoch 27/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1402 - acc: 0.5026\n",
      "Epoch 28/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1396 - acc: 0.5030\n",
      "Epoch 29/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1392 - acc: 0.5027\n",
      "Epoch 30/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1385 - acc: 0.5039\n",
      "Train on 81890 samples\n",
      "Epoch 1/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.3206 - acc: 0.3255\n",
      "Epoch 2/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.2516 - acc: 0.3868\n",
      "Epoch 3/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.2080 - acc: 0.4716\n",
      "Epoch 4/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1684 - acc: 0.4921\n",
      "Epoch 5/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1552 - acc: 0.4933\n",
      "Epoch 6/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1516 - acc: 0.4943\n",
      "Epoch 7/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1494 - acc: 0.4949\n",
      "Epoch 8/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1481 - acc: 0.4957\n",
      "Epoch 9/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1471 - acc: 0.4962\n",
      "Epoch 10/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1462 - acc: 0.4963\n",
      "Epoch 11/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1454 - acc: 0.4965\n",
      "Epoch 12/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1447 - acc: 0.4974\n",
      "Epoch 13/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1440 - acc: 0.4976\n",
      "Epoch 14/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1434 - acc: 0.4983\n",
      "Epoch 15/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1428 - acc: 0.4985\n",
      "Epoch 16/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1421 - acc: 0.4990\n",
      "Epoch 17/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1415 - acc: 0.4991\n",
      "Epoch 18/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1408 - acc: 0.4998\n",
      "Epoch 19/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1400 - acc: 0.5002\n",
      "Epoch 20/30\n",
      "81890/81890 [==============================] - 1s 9us/sample - loss: 1.1393 - acc: 0.5000\n",
      "Epoch 21/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1387 - acc: 0.5013\n",
      "Epoch 22/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1380 - acc: 0.5008\n",
      "Epoch 23/30\n",
      "81890/81890 [==============================] - 1s 9us/sample - loss: 1.1373 - acc: 0.5017\n",
      "Epoch 24/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1368 - acc: 0.5017\n",
      "Epoch 25/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1361 - acc: 0.5018\n",
      "Epoch 26/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1354 - acc: 0.5028\n",
      "Epoch 27/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1348 - acc: 0.5032\n",
      "Epoch 28/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1337 - acc: 0.5044\n",
      "Epoch 29/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1325 - acc: 0.5045\n",
      "Epoch 30/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1313 - acc: 0.5055\n",
      "Train on 81890 samples\n",
      "Epoch 1/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.3162 - acc: 0.3796\n",
      "Epoch 2/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.2305 - acc: 0.4792\n",
      "Epoch 3/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1928 - acc: 0.4897\n",
      "Epoch 4/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1718 - acc: 0.4933\n",
      "Epoch 5/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1606 - acc: 0.4956\n",
      "Epoch 6/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1552 - acc: 0.4960\n",
      "Epoch 7/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1524 - acc: 0.4968\n",
      "Epoch 8/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1498 - acc: 0.4977\n",
      "Epoch 9/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1474 - acc: 0.4984\n",
      "Epoch 10/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1456 - acc: 0.4984\n",
      "Epoch 11/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1443 - acc: 0.4992\n",
      "Epoch 12/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1430 - acc: 0.5005\n",
      "Epoch 13/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1419 - acc: 0.5010\n",
      "Epoch 14/30\n",
      "81890/81890 [==============================] - 1s 13us/sample - loss: 1.1409 - acc: 0.5013\n",
      "Epoch 15/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1399 - acc: 0.5021\n",
      "Epoch 16/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1388 - acc: 0.5025\n",
      "Epoch 17/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1379 - acc: 0.5022\n",
      "Epoch 18/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1369 - acc: 0.5033\n",
      "Epoch 19/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1358 - acc: 0.5041\n",
      "Epoch 20/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1349 - acc: 0.5048\n",
      "Epoch 21/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1336 - acc: 0.5046\n",
      "Epoch 22/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1326 - acc: 0.5054\n",
      "Epoch 23/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1314 - acc: 0.5059\n",
      "Epoch 24/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1301 - acc: 0.5069\n",
      "Epoch 25/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1288 - acc: 0.5068\n",
      "Epoch 26/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1278 - acc: 0.5069\n",
      "Epoch 27/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1271 - acc: 0.5075\n",
      "Epoch 28/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1263 - acc: 0.5069\n",
      "Epoch 29/30\n",
      "81890/81890 [==============================] - 1s 11us/sample - loss: 1.1256 - acc: 0.5079\n",
      "Epoch 30/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1250 - acc: 0.5076\n",
      "Train on 81890 samples\n",
      "Epoch 1/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.3104 - acc: 0.4044\n",
      "Epoch 2/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.2219 - acc: 0.4845\n",
      "Epoch 3/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1837 - acc: 0.4959\n",
      "Epoch 4/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1659 - acc: 0.4970\n",
      "Epoch 5/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1571 - acc: 0.4974\n",
      "Epoch 6/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1524 - acc: 0.4982\n",
      "Epoch 7/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1498 - acc: 0.4983\n",
      "Epoch 8/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1481 - acc: 0.4995\n",
      "Epoch 9/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1467 - acc: 0.4996\n",
      "Epoch 10/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1454 - acc: 0.4997\n",
      "Epoch 11/30\n",
      "81890/81890 [==============================] - 1s 6us/sample - loss: 1.1443 - acc: 0.4997\n",
      "Epoch 12/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1431 - acc: 0.4997\n",
      "Epoch 13/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1421 - acc: 0.5008\n",
      "Epoch 14/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1410 - acc: 0.5005\n",
      "Epoch 15/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1396 - acc: 0.5008\n",
      "Epoch 16/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1387 - acc: 0.5016\n",
      "Epoch 17/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1370 - acc: 0.5024\n",
      "Epoch 18/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1359 - acc: 0.5031\n",
      "Epoch 19/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1345 - acc: 0.5039\n",
      "Epoch 20/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1333 - acc: 0.5045\n",
      "Epoch 21/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1322 - acc: 0.5053\n",
      "Epoch 22/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1312 - acc: 0.5059\n",
      "Epoch 23/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1303 - acc: 0.5055\n",
      "Epoch 24/30\n",
      "81890/81890 [==============================] - 1s 6us/sample - loss: 1.1297 - acc: 0.5063\n",
      "Epoch 25/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1290 - acc: 0.5063\n",
      "Epoch 26/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1283 - acc: 0.5067\n",
      "Epoch 27/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1279 - acc: 0.5066\n",
      "Epoch 28/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1272 - acc: 0.5074\n",
      "Epoch 29/30\n",
      "81890/81890 [==============================] - 1s 13us/sample - loss: 1.1269 - acc: 0.5067\n",
      "Epoch 30/30\n",
      "81890/81890 [==============================] - 1s 9us/sample - loss: 1.1265 - acc: 0.5075\n",
      "Train on 81890 samples\n",
      "Epoch 1/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.3154 - acc: 0.4118\n",
      "Epoch 2/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.2343 - acc: 0.4675\n",
      "Epoch 3/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1846 - acc: 0.4927\n",
      "Epoch 4/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1598 - acc: 0.4967\n",
      "Epoch 5/30\n",
      "81890/81890 [==============================] - 1s 9us/sample - loss: 1.1505 - acc: 0.4974\n",
      "Epoch 6/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1458 - acc: 0.4984\n",
      "Epoch 7/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1426 - acc: 0.4990\n",
      "Epoch 8/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1400 - acc: 0.5002\n",
      "Epoch 9/30\n",
      "81890/81890 [==============================] - 1s 9us/sample - loss: 1.1381 - acc: 0.5010\n",
      "Epoch 10/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1365 - acc: 0.5024\n",
      "Epoch 11/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1351 - acc: 0.5024\n",
      "Epoch 12/30\n",
      "81890/81890 [==============================] - 1s 6us/sample - loss: 1.1338 - acc: 0.5042\n",
      "Epoch 13/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1327 - acc: 0.5039\n",
      "Epoch 14/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1317 - acc: 0.5050\n",
      "Epoch 15/30\n",
      "81890/81890 [==============================] - 1s 8us/sample - loss: 1.1309 - acc: 0.5050\n",
      "Epoch 16/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1298 - acc: 0.5060\n",
      "Epoch 17/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1290 - acc: 0.5065\n",
      "Epoch 18/30\n",
      "81890/81890 [==============================] - 1s 7us/sample - loss: 1.1282 - acc: 0.5065\n",
      "Epoch 19/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1275 - acc: 0.5074\n",
      "Epoch 20/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1266 - acc: 0.5070\n",
      "Epoch 21/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1262 - acc: 0.5075\n",
      "Epoch 22/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1255 - acc: 0.5078\n",
      "Epoch 23/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1248 - acc: 0.5080\n",
      "Epoch 24/30\n",
      "81890/81890 [==============================] - 0s 6us/sample - loss: 1.1243 - acc: 0.5086\n",
      "Epoch 25/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1238 - acc: 0.5082\n",
      "Epoch 26/30\n",
      "81890/81890 [==============================] - 0s 4us/sample - loss: 1.1233 - acc: 0.5087\n",
      "Epoch 27/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1229 - acc: 0.5088\n",
      "Epoch 28/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1225 - acc: 0.5094\n",
      "Epoch 29/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1220 - acc: 0.5097\n",
      "Epoch 30/30\n",
      "81890/81890 [==============================] - 0s 5us/sample - loss: 1.1217 - acc: 0.5098\n",
      "Train on 81891 samples\n",
      "Epoch 1/30\n",
      "81891/81891 [==============================] - 0s 5us/sample - loss: 1.2992 - acc: 0.4175\n",
      "Epoch 2/30\n",
      "81891/81891 [==============================] - 0s 6us/sample - loss: 1.2174 - acc: 0.4740\n",
      "Epoch 3/30\n",
      "81891/81891 [==============================] - 0s 6us/sample - loss: 1.1863 - acc: 0.4879\n",
      "Epoch 4/30\n",
      "81891/81891 [==============================] - 0s 5us/sample - loss: 1.1695 - acc: 0.4932\n",
      "Epoch 5/30\n",
      "81891/81891 [==============================] - 1s 6us/sample - loss: 1.1601 - acc: 0.4946\n",
      "Epoch 6/30\n",
      "81891/81891 [==============================] - 1s 7us/sample - loss: 1.1550 - acc: 0.4966\n",
      "Epoch 7/30\n",
      "81891/81891 [==============================] - 1s 8us/sample - loss: 1.1521 - acc: 0.4968\n",
      "Epoch 8/30\n",
      "81891/81891 [==============================] - 1s 7us/sample - loss: 1.1502 - acc: 0.4974\n",
      "Epoch 9/30\n",
      "81891/81891 [==============================] - 0s 5us/sample - loss: 1.1488 - acc: 0.4972\n",
      "Epoch 10/30\n",
      "81891/81891 [==============================] - 0s 5us/sample - loss: 1.1477 - acc: 0.4982\n",
      "Epoch 11/30\n",
      "81891/81891 [==============================] - 1s 7us/sample - loss: 1.1465 - acc: 0.4976\n",
      "Epoch 12/30\n",
      "81891/81891 [==============================] - 0s 6us/sample - loss: 1.1456 - acc: 0.4984\n",
      "Epoch 13/30\n",
      "81891/81891 [==============================] - 1s 6us/sample - loss: 1.1447 - acc: 0.4988\n",
      "Epoch 14/30\n",
      "81891/81891 [==============================] - 0s 6us/sample - loss: 1.1441 - acc: 0.4990\n",
      "Epoch 15/30\n",
      "81891/81891 [==============================] - 1s 7us/sample - loss: 1.1435 - acc: 0.4989\n",
      "Epoch 16/30\n",
      "81891/81891 [==============================] - 1s 6us/sample - loss: 1.1427 - acc: 0.4992\n",
      "Epoch 17/30\n",
      "81891/81891 [==============================] - 1s 6us/sample - loss: 1.1420 - acc: 0.4997\n",
      "Epoch 18/30\n",
      "81891/81891 [==============================] - 0s 5us/sample - loss: 1.1413 - acc: 0.5000\n",
      "Epoch 19/30\n",
      "81891/81891 [==============================] - 0s 5us/sample - loss: 1.1408 - acc: 0.5003\n",
      "Epoch 20/30\n",
      "81891/81891 [==============================] - 1s 8us/sample - loss: 1.1399 - acc: 0.5006\n",
      "Epoch 21/30\n",
      "81891/81891 [==============================] - 0s 5us/sample - loss: 1.1393 - acc: 0.5006\n",
      "Epoch 22/30\n",
      "81891/81891 [==============================] - 1s 6us/sample - loss: 1.1385 - acc: 0.5011\n",
      "Epoch 23/30\n",
      "81891/81891 [==============================] - 0s 6us/sample - loss: 1.1376 - acc: 0.5013\n",
      "Epoch 24/30\n",
      "81891/81891 [==============================] - 1s 8us/sample - loss: 1.1369 - acc: 0.5022\n",
      "Epoch 25/30\n",
      "81891/81891 [==============================] - 1s 8us/sample - loss: 1.1363 - acc: 0.5024\n",
      "Epoch 26/30\n",
      "81891/81891 [==============================] - 1s 7us/sample - loss: 1.1356 - acc: 0.5036\n",
      "Epoch 27/30\n",
      "81891/81891 [==============================] - 1s 6us/sample - loss: 1.1349 - acc: 0.5034\n",
      "Epoch 28/30\n",
      "81891/81891 [==============================] - 1s 7us/sample - loss: 1.1343 - acc: 0.5036\n",
      "Epoch 29/30\n",
      "81891/81891 [==============================] - 1s 10us/sample - loss: 1.1337 - acc: 0.5032\n",
      "Epoch 30/30\n",
      "81891/81891 [==============================] - 1s 9us/sample - loss: 1.1333 - acc: 0.5041\n",
      "Baseline: 50.61% (0.37%)\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "estimator.fit(X_train,Y_train)\r\n",
    "y_preds = estimator.predict(X_test)\r\n",
    "# y_preds = np.argmax(estimator.predict(X_test), axis=-1)\r\n",
    "len(y_preds)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 72791 samples\n",
      "Epoch 1/30\n",
      "72791/72791 [==============================] - 1s 8us/sample - loss: 1.3358 - acc: 0.3578\n",
      "Epoch 2/30\n",
      "72791/72791 [==============================] - 1s 8us/sample - loss: 1.2347 - acc: 0.4705\n",
      "Epoch 3/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1809 - acc: 0.4875\n",
      "Epoch 4/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1628 - acc: 0.4924\n",
      "Epoch 5/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1562 - acc: 0.4949\n",
      "Epoch 6/30\n",
      "72791/72791 [==============================] - 1s 14us/sample - loss: 1.1531 - acc: 0.4960\n",
      "Epoch 7/30\n",
      "72791/72791 [==============================] - 1s 9us/sample - loss: 1.1513 - acc: 0.4971\n",
      "Epoch 8/30\n",
      "72791/72791 [==============================] - 0s 6us/sample - loss: 1.1501 - acc: 0.4978\n",
      "Epoch 9/30\n",
      "72791/72791 [==============================] - 0s 6us/sample - loss: 1.1492 - acc: 0.4982\n",
      "Epoch 10/30\n",
      "72791/72791 [==============================] - 0s 4us/sample - loss: 1.1482 - acc: 0.4977\n",
      "Epoch 11/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1474 - acc: 0.4983\n",
      "Epoch 12/30\n",
      "72791/72791 [==============================] - 0s 4us/sample - loss: 1.1465 - acc: 0.4990\n",
      "Epoch 13/30\n",
      "72791/72791 [==============================] - 0s 4us/sample - loss: 1.1458 - acc: 0.4988\n",
      "Epoch 14/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1450 - acc: 0.4992\n",
      "Epoch 15/30\n",
      "72791/72791 [==============================] - 0s 6us/sample - loss: 1.1443 - acc: 0.4993\n",
      "Epoch 16/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1436 - acc: 0.4998\n",
      "Epoch 17/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1427 - acc: 0.5002\n",
      "Epoch 18/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1420 - acc: 0.5002\n",
      "Epoch 19/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1412 - acc: 0.5004\n",
      "Epoch 20/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1405 - acc: 0.5007\n",
      "Epoch 21/30\n",
      "72791/72791 [==============================] - 0s 6us/sample - loss: 1.1398 - acc: 0.5011\n",
      "Epoch 22/30\n",
      "72791/72791 [==============================] - 0s 4us/sample - loss: 1.1392 - acc: 0.5008\n",
      "Epoch 23/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1386 - acc: 0.5009\n",
      "Epoch 24/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1379 - acc: 0.5010\n",
      "Epoch 25/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1375 - acc: 0.5008\n",
      "Epoch 26/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1368 - acc: 0.5011\n",
      "Epoch 27/30\n",
      "72791/72791 [==============================] - 0s 4us/sample - loss: 1.1362 - acc: 0.5016\n",
      "Epoch 28/30\n",
      "72791/72791 [==============================] - 0s 5us/sample - loss: 1.1356 - acc: 0.5016\n",
      "Epoch 29/30\n",
      "72791/72791 [==============================] - 0s 6us/sample - loss: 1.1355 - acc: 0.5010\n",
      "Epoch 30/30\n",
      "72791/72791 [==============================] - 0s 6us/sample - loss: 1.1347 - acc: 0.5014\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18198"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "\r\n",
    "cm = confusion_matrix(Y_test,y_preds)\r\n",
    "ax = plt.subplot()\r\n",
    "sns.heatmap(cm,annot=True,ax=ax)\r\n",
    "\r\n",
    "labels = target['mood']\r\n",
    "ax.set_xlabel('Predicted labels')\r\n",
    "ax.set_ylabel('True labels')\r\n",
    "ax.set_title('Confusion Matrix')\r\n",
    "ax.xaxis.set_ticklabels(labels)\r\n",
    "ax.yaxis.set_ticklabels(labels)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"Accuracy Score\",accuracy_score(Y_test,y_preds))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score 0.5055500604462029\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "preds = get_songs_features('7J0JC8aTQB6Di3874t0fuk')\r\n",
    "print(preds)\r\n",
    "preds_features = np.array(preds[0][6:]).reshape(-1,1).T\r\n",
    "print(preds_features)\r\n",
    "X = MinMaxScaler().fit_transform(preds_features)\r\n",
    "print(X)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(['TWILIGHT IN UPPER WEST', 'TRUTH', 'T-SQUARE', '7J0JC8aTQB6Di3874t0fuk', '1987-04-01', 24, 325306, 0.468, 0.325, 10, -8.148, 1, 0.0304, 0.29, 0.385, 0.158, 0.0788, 129.735, 4], ['name', 'album', 'artist', 'id', 'release_date', 'popularity', 'duration', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature'])\n",
      "[[ 3.25306e+05  4.68000e-01  3.25000e-01  1.00000e+01 -8.14800e+00\n",
      "   1.00000e+00  3.04000e-02  2.90000e-01  3.85000e-01  1.58000e-01\n",
      "   7.88000e-02  1.29735e+02  4.00000e+00]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "\r\n",
    "def predict_mood(id_song):\r\n",
    "    #Join the model and the scaler in a Pipeline\r\n",
    "    pip = Pipeline([('minmaxscaler',MinMaxScaler()),('keras',KerasClassifier(build_fn=base_model,   epochs=30,\r\n",
    "                                                                             batch_size=512,verbose=0))])\r\n",
    "    # pip = Pipeline([('minmaxscaler',MinMaxScaler()),('keras',estimator)])\r\n",
    "    #Fit the Pipeline\r\n",
    "    pip.fit(X2,encoded_y)\r\n",
    "\r\n",
    "    #Obtain the features of the song\r\n",
    "    preds = get_songs_features(id_song)\r\n",
    "    #Pre-process the features to input the Model\r\n",
    "    preds_features = np.array(preds[0][6:]).reshape(-1,1).T\r\n",
    "\r\n",
    "    #Predict the features of the song\r\n",
    "    results = pip.predict(preds_features)\r\n",
    "\r\n",
    "    mood = np.array(target['mood'][target['encode']==int(results)])\r\n",
    "    name_song = preds[0][0]\r\n",
    "    artist = preds[0][2]\r\n",
    "\r\n",
    "    return print(\"{0} by {1} is a {2} song\".format(name_song,artist,mood[0].upper()))\r\n",
    "    #print(f\"{name_song} by {artist} is a {mood[0].upper()} song\")\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "predict_mood('2UYdqPzh5pnfjtb6kW4tsi')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " by Jun Shibata is a SAD song\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "51a9663a131f1b5758c45b97a2d6917c8ae86b33e231c3733631cbc7265cfc89"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}